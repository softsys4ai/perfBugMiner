"Total error: nan" for neural network model

Hi
I have randomly generated exponential signal. I am training the network to predict y values depending on the random time constant (tau). I have added one hidden layer and used gardient descent for optimization. The code runs fine, but it doesnt print error properly. I get this - ('Total Error: ', nan)
here is my code-
`import tensorflow as tf
import numpy as np
import random
input data
lorange= 1
hirange= 10
amplitude= random.uniform(-10,10)
t= 10
random.seed()
tau=random.uniform(lorange,hirange)
def generate_data(randomsignal):
x= np.arange(t)
y= amplitude*np.exp(-x/tau)
return x, y
#tensors for input data
x_input= tf.placeholder(tf.float32, shape=(10,))# t=10
y_input= tf.placeholder(tf.float32, shape=(10,))
#use 10 neurons-- just one layer for now
weights_1= tf.Variable(tf.truncated_normal([10,10], stddev= .1))
bias_1= tf.Variable(.1)
#hidden output
hidden_output= tf.nn.relu(tf.matmul(tf.reshape(x_input,[1,10]), weights_1) + bias_1)
weights_2 = tf.Variable(tf.truncated_normal([10, 10], stddev=.1))
bias_2= tf.Variable(.1)
calculated_output = tf.nn.softmax(tf.matmul(hidden_output, weights_2) +
bias_2)
cross_entropy = tf.reduce_mean(y_input * tf.log(calculated_output))
optimizer = tf.train.GradientDescentOptimizer(.5).minimize(cross_entropy)
sess = tf.Session()
#session
sess.run(tf.initialize_all_variables())
for i in range(1000):
x, y = generate_data(100)
sess.run(optimizer, feed_dict={x_input: x, y_input: y})
error = tf.reduce_sum(tf.abs(calculated_output - y_input))
x, y = generate_data(100)
print("Total Error: ", sess.run(error, feed_dict={x_input: x, y_input: y}))`